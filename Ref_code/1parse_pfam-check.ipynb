{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import Bio\n",
    "from Bio import AlignIO\n",
    "import os, urllib, gzip, re\n",
    "\n",
    "data_dir='data_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['Pfam-A.full.gz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfam_file = os.path.join(data_dir, 'pfam.npy')\n",
    "\n",
    "pfam = []\n",
    "with gzip.open(os.path.join(data_dir, 'Pfam-A.full.gz'), 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if line[:7] == '#=GF AC':\n",
    "            \n",
    "            ## name of PF (e.g., PF10417)\n",
    "            ac = line.split(' ')[4][:-1].split('.')[0]            \n",
    "            pfam.append([ac, 0, 0, 0]) \n",
    "            #pfam.append(ac)\n",
    "      \n",
    "        # 2018.12.03: test\n",
    "        #pfam.append(line)\n",
    "        if i == 50000: break        \n",
    "            \n",
    "pfam = np.array(pfam)\n",
    "n_pfam = len(pfam)\n",
    "\n",
    "#print(pfam.shape)\n",
    "#print(pfam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse multiple sequence alignments file with Biopython\n",
    "alignments = AlignIO.parse(gzip.open(os.path.join(data_dir, 'Pfam-A.full.gz'), 'r'),'stockholm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each pfam/msa\n",
    "for i, a in enumerate(alignments):\n",
    "    \n",
    "    # test with the first pfam in the downloaded data (PF10417)\n",
    "    if i > 0: break   \n",
    "    \n",
    "    # local directory associated with pfam\n",
    "    pfam_dir = os.path.join(data_dir, 'Pfam-A.full', pfam[i, 0])\n",
    "\n",
    "    try:\n",
    "        os.makedirs(pfam_dir)\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "    # number of residues/sequences in alignment\n",
    "    n_residue = a.get_alignment_length()    \n",
    "    n_sequence = len(a)\n",
    "    \n",
    "    #print('n_residue,n_sequence:')\n",
    "    #print(n_residue,n_sequence)\n",
    "\n",
    "    #------------------------------------------------------------------\n",
    "    # msa: residues symbols\n",
    "    # pdb_refs: references to pdb\n",
    "    msa = np.empty((n_residue, n_sequence), dtype=str)\n",
    "    pdb_refs = []\n",
    "    \n",
    "    # for each sequence in alignment\n",
    "    # 'a' is a BioPython object that corresponds to a list of sequences in an MSA, \n",
    "    # this will iterate through the sequences            \n",
    "    for j, seq in enumerate(a):\n",
    "        # store residue symbols in lowercase\n",
    "        # The actual list of residues is in the 'seq' member variable of 'seq', \n",
    "        # this converts those letters to lowercase\n",
    "        #msa[:, j] = np.array(seq.seq.lower())\n",
    "        msa[:, j] = np.array(seq.seq)  # 2018.12.03: Tai\n",
    "    \n",
    "        # msa[:,j] is aligned sequence j (or t in Tai's notation) \n",
    "        #print('msa[:,j]')\n",
    "        #print(msa[:, j])\n",
    "        \n",
    "        # store uniprot sequence id. This splits 'seq_id' on either '/' or '-' characters, \n",
    "        # so that 'id-0/100' splits into ['id', '0', '100']\n",
    "        uniprot_id, uniprot_start, uniprot_end = re.split('[/-]', seq.id)\n",
    "        \n",
    "        # extract pdb refs if they are present. 'dbxrefs' is the member variable of the Biopython\n",
    "        # object seq that contains pdb cross-reference info\n",
    "        refs = seq.dbxrefs\n",
    "        #print(refs)\n",
    "        \n",
    "        # if refs is an empty list, i.e. [], then continue to the next seq in the for loop        \n",
    "        if not refs:\n",
    "            continue\n",
    "            \n",
    "        # for each element in the the list 'refs'            \n",
    "        for ref in refs:\n",
    "            #print('ref:')\n",
    "            #print(ref) # 'PDB; 3KB6 B; 106-296'\n",
    "            \n",
    "            # remove white space and split on ';' so that ' PDB;XYZA;0-100 ' becomes ['PDB', 'XYZA', '0-100']                    \n",
    "            ref = ref.replace(' ', '').split(';')\n",
    "            if ref[0] == 'PDB':\n",
    "                # split id and chain info so that pdb_id='XYZ' and chain='A' continuing with the same example                        \n",
    "                pdb_id, chain = ref[1][:-1], ref[1][-1]\n",
    "                \n",
    "                # split '0-100' to ['0', '100']\n",
    "                pdb_start_end = ref[2].split('-')\n",
    "                if len(pdb_start_end) == 2:\n",
    "                    pdb_start, pdb_end = pdb_start_end                    \n",
    "                # If for some reason pdb_start_end is not a list of length 2, then continue to the next seq, \n",
    "                # this is a bit hacky but I found it necessary for a few apparently ill-formatted cross-references    \n",
    "                else:\n",
    "                    continue\n",
    "                pdb_refs.append([pfam[i,0],j-1,uniprot_id,uniprot_start,uniprot_end,pdb_id,chain,pdb_start,pdb_end])\n",
    "                # pfam[i,0] : pfam id (PF10417), j: sequence h pdb_ref\n",
    "                \n",
    "                #print('pdb_refs:')\n",
    "                #print(pfam[i, 0],j-1,uniprot_id, uniprot_start,uniprot_end,pdb_id,chain,pdb_start,pdb_end)\n",
    "                \n",
    "    # save an alignment matrix as a numpy binary for each MSA\n",
    "    np.save(os.path.join(pfam_dir,'msa.npy'),msa)\n",
    "    \n",
    "    # save the pdb cross reference info as a numpy binary for each MSA\n",
    "    np.save(os.path.join(pfam_dir,'pdb_refs.npy'), pdb_refs)\n",
    "            \n",
    "    n_pdb_ref = len(pdb_refs)\n",
    "    pfam[i, 1:] = n_residue, n_sequence, n_pdb_ref\n",
    "          \n",
    "np.save(pfam_file, pfam)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-' '-' '-' ... '-' '-' '-']\n"
     ]
    }
   ],
   "source": [
    "print(msa[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n"
     ]
    }
   ],
   "source": [
    "# compile all pdb_refs having pdb (n_pdb > 0)\n",
    "pdb_refs_file = os.path.join(data_dir, 'pdb_refs.npy')\n",
    "# this file takes a lot of work to generate, so if it is cached already, then load it, else generate and cache it\n",
    "if os.path.exists(pdb_refs_file):\n",
    "    print('load')\n",
    "    pdb_refs = np.load(pdb_refs_file)\n",
    "else:\n",
    "    # find pfam has pdb\n",
    "    # number of pdb\n",
    "    n_pdb_refs = pfam[:, 3].astype(int)\n",
    "    has_pdb_refs = n_pdb_refs > 0\n",
    "    n_pdb_refs = n_pdb_refs[has_pdb_refs]\n",
    "    pfam_with_pdb = pfam[has_pdb_refs, 0]\n",
    "    \n",
    "    print(pfam_with_pdb)\n",
    "    \n",
    "    # read pdb_refs.npy from folder of pfam having pdb\n",
    "    # the first one\n",
    "    refs = os.path.join(data_dir, 'Pfam-A.full', pfam_with_pdb[0],'pdb_refs.npy')\n",
    "    pdb_refs = np.load(refs)\n",
    "    for fam in pfam_with_pdb[1:]:\n",
    "        print('add the 2nd, 3rd,... to the 1st')        \n",
    "        refs = np.load(os.path.join(data_dir, 'Pfam-A.full', fam, 'pdb_refs.npy'))\n",
    "        pdb_refs = np.vstack([pdb_refs, refs])\n",
    "    np.save(pdb_refs_file, pdb_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pfam and pdb_refs to pandas dataframes\n",
    "pfam = pd.DataFrame(index=pfam[:, 0],data=pfam[:, 1:],columns=['res', 'seq', 'pdb_refs'],dtype=int)\n",
    "pdb_refs = pd.DataFrame(index=pdb_refs[:, 0],data=pdb_refs[:, 1:],columns=[\n",
    "        'seq', 'uniprot_id', 'uniprot_start', 'uniprot_end', 'pdb_id', 'chain', 'pdb_start', 'pdb_end'])\n",
    "cols = ['seq', 'uniprot_start', 'uniprot_end', 'pdb_start', 'pdb_end']\n",
    "pdb_refs[cols] = pdb_refs[cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows where the length between uniprot start/end is different from pdb start/end\n",
    "cols = ['uniprot_start', 'uniprot_end', 'pdb_start', 'pdb_end']\n",
    "start_end = pdb_refs[cols].values\n",
    "consistent_length = np.diff(start_end[:, :2], axis=1) == np.diff(start_end[:, 2:], axis=1)\n",
    "pdb_refs = pdb_refs[consistent_length]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
